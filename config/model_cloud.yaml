model:
  name: "Qwen/Qwen2.5-Coder-1.5B"
  device: "cuda"
  quantization: "4bit"         # 4-bit via bitsandbytes
  max_length: 4096
  temperature: 0.7
  top_p: 0.9
  cache_dir: "./models/qwen_cache"

constitutional:
  critique_enabled: true
  revision_enabled: true
  max_revisions: 3
